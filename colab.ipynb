{
  "cells": [       
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LostRuins/koboldcpp/blob/concedo/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
	{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Welcome to the Official KoboldCpp Colab Notebook\r\n",
        "It's really easy to get started. Just press the two Play buttons below, and then connect to the cloudflare URL shown at the end. \r\nYou can also change the model URL to use any GGUF model from Huggingface."
      ]
    }, 
	{
      "cell_type": "code",
      "metadata": {},
	  "execution_count": null,
	  "outputs": [],
      "source": [
        "#@title <-- Tap this if you play on Mobile { display-mode: \"form\" }\r\n",
        "%%html\r\n",
        "<b>Press play on the music player to keep the tab alive, then start KoboldCpp below</b><br/>\r\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uJS9i_Dltv8Y"
      },
      "outputs": [],
      "source": [
        "#@title <b>v-- Enter your model below and then click this to start Koboldcpp</b>\r\n",
        "\r\n",
        "Model = \"https://huggingface.co/KoboldAI/LLaMA2-13B-Tiefighter-GGUF/resolve/main/LLaMA2-13B-Tiefighter.Q4_K_S.gguf\" #@param [\"\"]{allow-input: true}\r\n",
        "Layers = 43 #@param [43]{allow-input: true}\r\n",
        "\r\n",
        "%cd /content\r\n",
        "!git clone https://github.com/LostRuins/koboldcpp\r\n",
        "%cd /content/koboldcpp\r\n",
        "!make LLAMA_CUBLAS=1\r\n",
        "\r\n",
        "!wget $Model -O model.ggml\r\n",
        "!wget -c https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\r\n",
        "!chmod +x cloudflared-linux-amd64\r\n",
        "!nohup ./cloudflared-linux-amd64 tunnel --url http://localhost:5001 &\r\n",
        "!sleep 8\r\n",
        "!cat nohup.out\r\n",
        "!python koboldcpp.py model.ggml --usecublas 0 mmq --multiuser --gpulayers $Layers --hordeconfig concedo 1 1 --onready \"cat nohup.out\"\r\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "",
      "gpuType": "T4",
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}